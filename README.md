# Improving Value Estimation Critically Enhances Vanilla Policy Gradient

This repository contains the code and implementation details in the paper **Improving Value Estimation Critically Enhances Vanilla Policy Gradient**.

The empirical results shown in the paper are obtained by running `examples/mujoco/run_experiments.sh`, which is adopted from **[Tianshou](https://github.com/thu-ml/tianshou)**. To reproduce these results in an easier way, we also provide a single-file implementation `VPG_single_file.py` built from **[CleanRL](https://github.com/vwxyzjn/cleanrl)**, which removes all non-essential components from the original implementation.
